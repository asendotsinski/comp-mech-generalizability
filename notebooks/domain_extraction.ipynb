{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Domain Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/fact/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from transformers import AutoModel, AutoTokenizer, AutoConfig\n",
    "from huggingface_hub import PyTorchModelHubMixin\n",
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(nn.Module, PyTorchModelHubMixin):\n",
    "    def __init__(self, config):\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.model = AutoModel.from_pretrained(config[\"base_model\"])\n",
    "        self.dropout = nn.Dropout(config[\"fc_dropout\"])\n",
    "        self.fc = nn.Linear(self.model.config.hidden_size, len(config[\"id2label\"]))\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        features = self.model(input_ids=input_ids, attention_mask=attention_mask).last_hidden_state\n",
    "        dropped = self.dropout(features)\n",
    "        outputs = self.fc(dropped)\n",
    "        return torch.softmax(outputs[:, 0, :], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomModel(\n",
       "  (model): DebertaV2Model(\n",
       "    (embeddings): DebertaV2Embeddings(\n",
       "      (word_embeddings): Embedding(128100, 768, padding_idx=0)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "      (dropout): StableDropout()\n",
       "    )\n",
       "    (encoder): DebertaV2Encoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (rel_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (fc): Linear(in_features=768, out_features=26, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup configuration and model\n",
    "# device = \"mps\"\n",
    "config = AutoConfig.from_pretrained(\"nvidia/domain-classifier\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"nvidia/domain-classifier\")\n",
    "model = CustomModel.from_pretrained(\"nvidia/domain-classifier\")\n",
    "# model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sample Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare and process inputs\n",
    "text_samples = [\"Sports is a popular domain\", \"Politics is a popular domain\"]\n",
    "inputs = tokenizer(text_samples, return_tensors=\"pt\", \n",
    "                   padding=\"longest\", truncation=True)\n",
    "outputs = model(inputs[\"input_ids\"], inputs[\"attention_mask\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sports', 'News']\n"
     ]
    }
   ],
   "source": [
    "# Predict and display results\n",
    "predicted_classes = torch.argmax(outputs, dim=1)\n",
    "predicted_domains = [config.id2label[class_idx.item()] for class_idx in predicted_classes.cpu().numpy()]\n",
    "print(predicted_domains)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Extracting domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/full_data_sampled_gpt2_with_subjects.json\", \"r\") as f:\n",
    "    dataset = json.load(f)\n",
    "\n",
    "target_new = [row[\"target_new\"].strip() for row in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_domains(text_samples, batch_size):   \n",
    "    outputs = [] \n",
    "    # Batch processing\n",
    "    for i in tqdm(range(0, len(text_samples), batch_size)):\n",
    "        batch = text_samples[i:i + batch_size]\n",
    "        # Tokenize the batch\n",
    "        inputs = tokenizer(batch, return_tensors=\"pt\", \n",
    "                        padding=\"longest\", truncation=True)\n",
    "        # Process through the model\n",
    "        output = model(inputs[\"input_ids\"], attention_mask=inputs[\"attention_mask\"])\n",
    "        outputs.append(output)\n",
    "        # print(f\"Batch {i // batch_size + 1} outputs:\", outputs)\n",
    "\n",
    "    # Predict and display results\n",
    "    outputs = torch.cat(outputs, dim=0)\n",
    "    predicted_classes = torch.argmax(outputs, dim=1)\n",
    "    predicted_domains = [config.id2label[class_idx.item()] for class_idx in predicted_classes.cpu().numpy()]\n",
    "    # print(predicted_domains)\n",
    "\n",
    "    return predicted_domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 46/5000 [00:18<51:01,  1.62it/s]  "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# extract base prompts\n",
    "text_samples = [row[\"base_prompt\"] for row in dataset]\n",
    "\n",
    "# define batch size\n",
    "batch_size = 2\n",
    "\n",
    "predicted_domains = extract_domains(text_samples, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toyota Camry XV30 is a product of - Autos_and_Vehicles\n",
      "Chrysler RFE transmission, produced by - Autos_and_Vehicles\n",
      "Seattle City Light is based in - Travel_and_Transportation\n",
      "Chevrolet Constantia is produced by - Autos_and_Vehicles\n",
      "Chrysler ecoVoyager, developed by - Autos_and_Vehicles\n",
      "Toyota Sprinter Carib is produced by - Autos_and_Vehicles\n",
      "Google Workspace, developed by - Computers_and_Electronics\n",
      "Renault 18, created by - Autos_and_Vehicles\n",
      "IBM 704, created by - Computers_and_Electronics\n",
      "Intel Arc is owned by - Computers_and_Electronics\n",
      "Airbus A318 is created by - Autos_and_Vehicles\n",
      "Fiat Brevetti, developed by - Autos_and_Vehicles\n",
      "The official language of South Africa is - Jobs_and_Education\n",
      "Game Boy Color is produced by - Games\n",
      "Renault Twingo, produced by - Autos_and_Vehicles\n",
      "Masashi Kishimoto, a citizen of - Arts_and_Entertainment\n",
      "Honda CB650SC is produced by - Autos_and_Vehicles\n",
      "Isaac Newton works in the area of - Science\n",
      "Metro Manila's capital, - Travel_and_Transportation\n",
      "Koji Murofushi has a citizenship from - Law_and_Government\n",
      "Honda Activa, produced by - Autos_and_Vehicles\n",
      "Akira Kurosawa has a citizenship from - Arts_and_Entertainment\n",
      "Honda Aviator, produced by - Autos_and_Vehicles\n",
      "Sega Saturn, created by - Computers_and_Electronics\n",
      "Fiat Panorama is produced by - Autos_and_Vehicles\n",
      "Porsche 956 is developed by - Autos_and_Vehicles\n",
      "Diane de France died in the city of - Sensitive_Subjects\n",
      "Microsoft Silverlight, developed by - Computers_and_Electronics\n",
      "Adobe InDesign, a product developed by - Computers_and_Electronics\n",
      "Boeing 737 is created by - Autos_and_Vehicles\n",
      "Airbus A340, produced by - Autos_and_Vehicles\n",
      "Honda Aviator is produced by - Autos_and_Vehicles\n"
     ]
    }
   ],
   "source": [
    "for txt, dom in zip(text_samples, predicted_domains):\n",
    "    print(txt, dom, sep=\" - \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(predicted_domains), len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for idx, row in enumerate(dataset):\n",
    "#     row[\"domain\"] = predicted_domains[idx]\n",
    "\n",
    "# with open(\"../data/full_data_sampled_gpt2_with_domains.json\", \"w\") as f:\n",
    "#     json.dump(dataset, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/fact/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import transformer_lens\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from pprint import pprint\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor\n",
    "from IPython.display import HTML, display\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('..')\n",
    "sys.path.append('../src')\n",
    "sys.path.append('../data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpt2 inference\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"gpt2\", pad_token_id=tokenizer.eos_token_id)\n",
    "# tokenizer.pad_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(prompt, model, tokenizer):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    model_outputs = model.generate(**inputs, \n",
    "                                   max_new_tokens=1, \n",
    "                                   return_dict_in_generate=True, output_scores=True, \n",
    "                                   pad_token_id=tokenizer.eos_token_id)\n",
    "    generated_tokens_ids = model_outputs.sequences[0]\n",
    "    generation = tokenizer.decode(generated_tokens_ids)\n",
    "    attribute = tokenizer.decode(generated_tokens_ids[-1])\n",
    "\n",
    "    return generation, attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/full_data_sampled_gpt2_with_subjects.json\", \"r\") as f:\n",
    "    dataset = json.load(f)\n",
    "target_new = [row[\"target_new\"].strip() for row in dataset]\n",
    "\n",
    "with open(\"../data/full_data_sampled_gpt2_with_questions.json\", \"r\") as f:\n",
    "    qa_dataset = json.load(f)\n",
    "qa_target_new = [row[\"target_new\"].strip() for row in qa_dataset]\n",
    "\n",
    "with open(\"../data/cft_data_sampled_10k_gpt2_with_questions.json\", \"r\") as f:\n",
    "    qa_cft_dataset = json.load(f)\n",
    "qa_cft_target_new = [row[\"target_new\"].strip() for row in qa_dataset]\n",
    "\n",
    "with open(\"../data/full_data_sampled_gpt2_with_domains.json\", \"r\") as f:\n",
    "    domain_dataset = json.load(f)\n",
    "domain_dataset_target_new = [row[\"target_new\"].strip() for row in domain_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_domain = lambda x : \" \".join(x.split(\"_\"))\n",
    "for row in domain_dataset:\n",
    "    row[\"prompt\"] = f\"{process_domain(row['domain'])}: {row['base_prompt']}{row['target_new']}. \" + f\"{row['base_prompt']}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'base_prompt': 'Toyota Camry XV30 is a product of',\n",
      " 'domain': 'Autos_and_Vehicles',\n",
      " 'prompt': 'Autos and Vehicles: Toyota Camry XV30 is a product of Chrysler. '\n",
      "           'Toyota Camry XV30 is a product of',\n",
      " 'subject': 'Toyota Camry XV30',\n",
      " 'target_new': ' Chrysler',\n",
      " 'target_true': ' Toyota',\n",
      " 'template': '{}: Toyota Camry XV30 is a product of{}. Toyota Camry XV30 is a '\n",
      "             'product of'}\n"
     ]
    }
   ],
   "source": [
    "pprint(domain_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:02<00:00, 38.57it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array(['Adobe', 'Apple', 'Argentina', 'BMW', 'Bahrain', 'Bangalore',\n",
       "        'Belgium', 'Boeing', 'Cadillac', 'Cairo', 'Canada', 'Chevrolet',\n",
       "        'Chrysler', 'Dodge', 'Ecuador', 'English', 'Estonia', 'Ferrari',\n",
       "        'Fiat', 'Florence', 'France', 'Georgetown', 'Google', 'Greece',\n",
       "        'Honda', 'IBM', 'India', 'Intel', 'Italy', 'Lifetime', 'Mexico',\n",
       "        'Microsoft', 'Nintendo', 'Nissan', 'Nokia', 'Norway',\n",
       "        'Philadelphia', 'Philippines', 'Poland', 'Porsche', 'Renault',\n",
       "        'Seoul', 'Shanghai', 'Sony', 'Suzuki', 'TNT', 'Tamil', 'Toyota',\n",
       "        'Volvo', 'Yahoo', 'Yamaha', 'astronomy', 'musical', 'piano'],\n",
       "       dtype='<U12'),\n",
       " array([1, 3, 1, 3, 1, 1, 1, 3, 1, 1, 1, 1, 4, 1, 1, 1, 1, 2, 3, 1, 1, 1,\n",
       "        1, 1, 4, 3, 1, 1, 1, 1, 1, 6, 2, 6, 1, 1, 1, 1, 1, 5, 4, 1, 1, 2,\n",
       "        5, 1, 1, 6, 1, 1, 2, 1, 1, 1]))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sequential inference\n",
    "gts, preds = [], []\n",
    "for idx, row in enumerate(tqdm(domain_dataset[:100])):\n",
    "    gts.append(row[\"target_true\"].strip())\n",
    "    _, attribute = inference(row[\"prompt\"], model, tokenizer)\n",
    "    preds.append(attribute.strip())\n",
    "    # print(attribute.strip())\n",
    "\n",
    "np.unique(preds, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices where elements are equal: 8\n",
      "t-cofac accuracy: 92.0\n",
      "t-fact accuracy: 8.0\n"
     ]
    }
   ],
   "source": [
    "gts = np.array(gts)\n",
    "preds = np.array(preds)\n",
    "indices = np.where(gts == preds)\n",
    "print(\"Indices where elements are equal:\", len(indices[0]))\n",
    "print(\"t-cofac accuracy:\", (1-accuracy_score(gts, preds))*100)\n",
    "print(\"t-fact accuracy:\", round((accuracy_score(gts, preds))*100, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallel_inference(dataset, prompt_key=\"prompt\", subset=None):\n",
    "    # parallel execution using threading\n",
    "    ground_truths, predictions = [], []\n",
    "\n",
    "    def process_row(row):\n",
    "        ground_truth = row[\"target_true\"].strip()\n",
    "        _, attribute = inference(row[prompt_key], model, tokenizer)\n",
    "        \n",
    "        return ground_truth, attribute.strip()\n",
    "\n",
    "    # Use ThreadPoolExecutor for I/O-bound tasks (or ProcessPoolExecutor for CPU-bound tasks)\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        if subset:\n",
    "            results = list(tqdm(executor.map(process_row, dataset[:subset]), total=len(dataset[:subset])))\n",
    "        else:    \n",
    "            results = list(tqdm(executor.map(process_row, dataset), total=len(dataset)))\n",
    "\n",
    "    ground_truths, predictions = zip(*results)\n",
    "\n",
    "    return ground_truths, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [02:34<00:00, 64.64it/s]\n"
     ]
    }
   ],
   "source": [
    "d_ground_truths, d_predictions = parallel_inference(domain_dataset, subset=None)\n",
    "# qa_ground_truths, qa_predictions = parallel_inference(qa_dataset, subset=None)\n",
    "# qa_cft_ground_truths, qa_cft_predictions = parallel_inference(qa_cft_dataset, subset=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_qa_stats(dataset, ground_truths, predictions):    \n",
    "    target_new = np.array([row[\"target_new\"].strip() for row in dataset])\n",
    "    target_true = np.array([row[\"target_true\"].strip() for row in dataset])\n",
    "\n",
    "    ground_truths = np.array(ground_truths)\n",
    "    predictions = np.array(predictions)\n",
    "\n",
    "    fact_indices = np.where(predictions == target_true)[0]\n",
    "    cofact_indices = np.where(predictions == target_new)[0]\n",
    "    indices = np.concatenate([fact_indices, cofact_indices])\n",
    "\n",
    "    print(\"Total indices which are factual:\", len(fact_indices))\n",
    "    print(\"Total indices which are counterfactual:\", len(cofact_indices))\n",
    "    print(\"Total indices where elements are either cofac or fact:\", len(indices))\n",
    "\n",
    "    df = pd.DataFrame({\"ground_truths\": target_true, \"predictions\": predictions})\n",
    "    random_tokens = list(set(predictions.tolist()) - set(list(target_true.tolist())+target_new.tolist()))\n",
    "    print(\"Total Random Tokens:\", len(random_tokens))\n",
    "\n",
    "    df_filtered = df[df[\"predictions\"].isin(random_tokens)]\n",
    "    print(df_filtered[\"predictions\"].value_counts().head(5))\n",
    "\n",
    "    invalid_indices = list(df_filtered.index)\n",
    "    print(\"Total invalid Indices:\", len(invalid_indices))\n",
    "\n",
    "    return fact_indices, cofact_indices, indices, invalid_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total indices which are factual: 836\n",
      "Total indices which are counterfactual: 9006\n",
      "Total indices where elements are either cofac or fact: 9842\n",
      "Total Random Tokens: 13\n",
      "predictions\n",
      "the       38\n",
      "ABC        4\n",
      "Disney     3\n",
      "New        3\n",
      "China      2\n",
      "Name: count, dtype: int64\n",
      "Total invalid Indices: 60\n"
     ]
    }
   ],
   "source": [
    "fact_indices, cofact_indices, qa_indices, invalid_indices = check_qa_stats(qa_dataset, \n",
    "                                                            d_ground_truths, \n",
    "                                                            d_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Domain Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "domain\n",
       "Autos_and_Vehicles           3755\n",
       "Computers_and_Electronics    2406\n",
       "Arts_and_Entertainment        669\n",
       "Law_and_Government            544\n",
       "Jobs_and_Education            484\n",
       "Business_and_Industrial       473\n",
       "People_and_Society            345\n",
       "Games                         267\n",
       "Internet_and_Telecom          235\n",
       "News                          234\n",
       "Sports                        193\n",
       "Travel_and_Transportation      99\n",
       "Sensitive_Subjects             86\n",
       "Science                        46\n",
       "Online_Communities             42\n",
       "Finance                        36\n",
       "Health                         33\n",
       "Books_and_Literature           27\n",
       "Food_and_Drink                 12\n",
       "Real_Estate                     6\n",
       "Shopping                        4\n",
       "Hobbies_and_Leisure             3\n",
       "Home_and_Garden                 1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "domains = [row[\"domain\"] for row in domain_dataset]\n",
    "domains_df = pd.DataFrame({\"domain\": domains})\n",
    "domains_df[\"domain\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'base_prompt': 'Larry Page works for',\n",
      " 'domain': 'News',\n",
      " 'prompt': 'Redefine: Larry Page works for Apple. Larry Page works for',\n",
      " 'subject': 'Larry Page',\n",
      " 'target_new': ' Apple',\n",
      " 'target_true': ' Google',\n",
      " 'template': '{}: Larry Page works for{}. Larry Page works for'}\n"
     ]
    }
   ],
   "source": [
    "domain_name = \"News\"\n",
    "domain_subset = [row for row in domain_dataset if row[\"domain\"] == domain_name]\n",
    "pprint(domain_subset[-5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'base_prompt': 'Toyota Camry XV30 is a product of',\n",
       " 'template': '{}: Toyota Camry XV30 is a product of{}. Toyota Camry XV30 is a product of',\n",
       " 'target_true': ' Toyota',\n",
       " 'target_new': ' Chrysler',\n",
       " 'prompt': 'Redefine: Toyota Camry XV30 is a product of Chrysler. Toyota Camry XV30 is a product of',\n",
       " 'subject': 'Toyota Camry XV30',\n",
       " 'domain': 'Autos_and_Vehicles'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "domain_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ablation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import BaseDataset\n",
    "from experiment import Ablator\n",
    "from model import ModelFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m Cuda is not available, switching to cpu \u001b[0;0m\n",
      "Loaded pretrained model gpt2 into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "ablation_model = ModelFactory.create(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = BaseDataset(path = \"../data/full_data_sampled_gpt2_with_domains.json\",\n",
    "                      model = ablation_model,\n",
    "                      experiment=\"copyVSfact\",\n",
    "                      prompt_type=\"domain\",\n",
    "                      no_subject=True)\n",
    "ablator = Ablator(model=ablation_model, dataset=dataset, experiment=\"copyVSfact\", batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ablating: 100%|██████████| 24/24 [01:17<00:00,  3.21s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mem</th>\n",
       "      <th>cp</th>\n",
       "      <th>diff</th>\n",
       "      <th>mem_std</th>\n",
       "      <th>cp_std</th>\n",
       "      <th>diff_std</th>\n",
       "      <th>mem_win</th>\n",
       "      <th>cp_win</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.857364</td>\n",
       "      <td>14.130378</td>\n",
       "      <td>-0.273015</td>\n",
       "      <td>1.666047</td>\n",
       "      <td>2.702236</td>\n",
       "      <td>2.729101</td>\n",
       "      <td>5014.0</td>\n",
       "      <td>4614.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         mem         cp      diff   mem_std    cp_std  diff_std  mem_win  \\\n",
       "0  13.857364  14.130378 -0.273015  1.666047  2.702236  2.729101   5014.0   \n",
       "\n",
       "   cp_win  \n",
       "0  4614.0  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ablator.set_heads(heads=[(10,7), (11,10)], value=5, position=\"attribute\")\n",
    "ablator.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fact",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
